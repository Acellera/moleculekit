{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voxelization tutorial\n",
    "This tutorial will introduce you to how to obtain voxel descriptors of pharmacophoric-like properties of your protein and ligands, ready for machine learning applications such as the ones used in KDeep, DeepSite and more. For more information and applications read the following references:\n",
    "\n",
    "* [DeepSite](https://doi.org/10.1093/bioinformatics/btx350)\n",
    "* [LigVoxel](https://doi.org/10.1093/bioinformatics/bty583)\n",
    "* [KDeep](https://doi.org/10.1021/acs.jcim.7b00650)\n",
    "* [BindScope](https://doi.org/10.1093/bioinformatics/bty758)\n",
    "\n",
    "This tutorial will only work with the VMD viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moleculekit.molecule import Molecule\n",
    "from moleculekit.tools.voxeldescriptors import getVoxelDescriptors, viewVoxelFeatures\n",
    "from moleculekit.tools.atomtyper import prepareProteinForAtomtyping\n",
    "from moleculekit.smallmol.smallmol import SmallMol\n",
    "from moleculekit.home import home\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's read our two favourite protein and ligand structures\n",
    "tut_data = home(dataDir='test-voxeldescriptors')\n",
    "prot = Molecule(os.path.join(tut_data, '3PTB.pdb'))\n",
    "slig = SmallMol(os.path.join(tut_data, 'benzamidine.mol2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atom typing for the protein requires the protein to be protonated and to include the atom bond information.\n",
    "Currently the Molecule contains does not contain all bond information as you can see by checking prot.bonds.\n",
    "`prepareProteinForAtomtyping` will perform most necessary operations such as removing non-protein atoms,\n",
    "adding hydrogens, guessing bonds and guessing protein chains but you can perform those manually as well.\n",
    "Take care however as the protonation will a) move atoms to optimize hydrogen networks b) add missing sidechains\n",
    "and c) the bond guessing can go wrong if atoms are very close to each other which can happen when adding sidechains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your structure is fully protonated and contains all bond information in prot.bonds skip this step!\n",
    "prot = prepareProteinForAtomtyping(prot)\n",
    "\n",
    "# We would suggest visualizing the results with prot.view(guessBonds=False) to show only the bonds \n",
    "# already stored in the Molecule. \n",
    "prot.view(guessBonds=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the voxel information for the protein.\n",
    "By default `getVoxelDescriptors` will calculate the bounding box of the molecule and grid it into voxels.\n",
    "As we don't use point properties but smooth them out over space, we will add 1 A buffer space around the protein \n",
    "for the voxelization grid so that the properties don't cut off at the edge of the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_vox, prot_centers, prot_N = getVoxelDescriptors(prot, buffer=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the voxels. This will visualize each voxel channel as a separate VMD molecule so that you can\n",
    "inspect each individually. You can play around with the IsoValue in the IsoSurface representation of each channel\n",
    "to inspect it in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot.view(guessBonds=False)\n",
    "viewVoxelFeatures(prot_vox, prot_centers, prot_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the ligand since it's small we could increase the voxel resolution if we so desire to 0.5 A instead of the default 1 A.\n",
    "lig_vox, lig_centers, lig_N = getVoxelDescriptors(slig, voxelsize=0.5, buffer=1)\n",
    "slig.view(guessBonds=False)\n",
    "viewVoxelFeatures(lig_vox, lig_centers, lig_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's use this data in pytorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform 3D convolutions we need to reshape the data to `(nsamples, nchannels, d, h, w)` with the last three\n",
    "dimensions corresponding to the 3D elements. Our data is in `(d*h*w, nchannels)` format so we first transpose \n",
    "and then reshape it. In this case it's a single sample so we just add a first dimension to the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchannels = prot_vox.shape[1]\n",
    "\n",
    "prot_vox_t = prot_vox.transpose().reshape([1, nchannels, prot_N[0], prot_N[1], prot_N[2]])\n",
    "prot_vox_t = torch.tensor(prot_vox_t.astype(np.float32))\n",
    "\n",
    "lig_vox_t = lig_vox.transpose().reshape([1, nchannels, lig_N[0], lig_N[1], lig_N[2]])\n",
    "lig_vox_t = torch.tensor(lig_vox_t.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just test is on a simple pytorch model with 3D convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(nchannels, 20, 5)  # (in_channels, out_channels, kernel_size)\n",
    "        self.conv2 = nn.Conv3d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "       x = F.relu(self.conv1(x))\n",
    "       return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "results = model.forward(lig_vox_t)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for this tutorial. Time to go ahead and create the next coolest voxel-based predictor!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
